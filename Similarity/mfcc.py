# -*- coding: utf-8 -*-
"""mfcc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zO5-bgcE66oiLsZE6OAluElUoBYek_VI
"""

!pip install essentia

import numpy, scipy, matplotlib.pyplot as plt, sklearn, librosa, urllib, IPython.display
import essentia, essentia.standard as ess
plt.rcParams['figure.figsize'] = (14,4)

"""[&larr; Back to Index](index.html)

# Mel Frequency Cepstral Coefficients (MFCCs)

The [mel frequency cepstral coefficients](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum) (MFCCs) of a signal are a small set of features (usually about 10-20) which concisely describe the overall shape of a spectral envelope. In MIR, it is often used to describe timbre.

Download an audio file:
"""

from google.colab import drive
drive.mount('/content/drive')

"""Plot the audio signal:"""

from librosa.display import waveplot
from librosa import load
x, fs = load('/content/drive/My Drive/PAS/Marina/MS-3.WAV')
waveplot(x, sr=fs)

"""Play the audio:"""

IPython.display.Audio(x, rate=fs)

y, fp = load('/content/drive/My Drive/PAS/Sami/SM-3.WAV')
waveplot(y, sr=fp)

IPython.display.Audio(y, rate=fp)

z, fq = load('/content/drive/My Drive/PAS/Maryam/SF-3.WAV')
waveplot(z, sr=fq)

IPython.display.Audio(z, rate=fq)

"""## `librosa.feature.mfcc`

[`librosa.feature.mfcc`](http://bmcfee.github.io/librosa/generated/librosa.feature.mfcc.html#librosa.feature.mfcc) computes MFCCs across an audio signal:
"""

mfccs = librosa.feature.mfcc(x, sr=fs)
print mfccs.shape

mfccs1 = librosa.feature.mfcc(y, sr=fp)
print mfccs1.shape

mfccs2 = librosa.feature.mfcc(z, sr=fq)
print mfccs2.shape

"""In this case, `mfcc` computed 20 MFCCs over 130 frames.

The very first MFCC, the 0th coefficient, does not convey information relevant to the overall shape of the spectrum. It only conveys a constant offset, i.e. adding a constant value to the entire spectrum. Therefore, many practitioners will discard the first MFCC when performing classification. For now, we will use the MFCCs as is.

Display the MFCCs:
"""

librosa.display.specshow(mfccs, sr=fs, x_axis='time')

librosa.display.specshow(mfccs1, sr=fp, x_axis='time')

librosa.display.specshow(mfccs2, sr=fq, x_axis='time')



"""### Feature Scaling

Let's scale the MFCCs such that each coefficient dimension has zero mean and unit variance:
"""

mfccs = sklearn.preprocessing.scale(mfccs, axis=1)
print mfccs.mean(axis=1)
print mfccs.var(axis=1)

print(mfccs)

mfccs1 = sklearn.preprocessing.scale(mfccs1, axis=1)
print mfccs1.mean(axis=1)
print mfccs1.var(axis=1)

mfccs2 = sklearn.preprocessing.scale(mfccs2, axis=1)
print mfccs2.mean(axis=1)
print mfccs2.var(axis=1)

"""Display the scaled MFCCs:"""

librosa.display.specshow(mfccs, sr=fs, x_axis='time')

librosa.display.specshow(mfccs1, sr=fp, x_axis='time')

librosa.display.specshow(mfccs2, sr=fq, x_axis='time')

"""## `essentia.standard.MFCC`

We can also use [`essentia.standard.MFCC`](http://essentia.upf.edu/documentation/reference/std_MFCC.html) to compute MFCCs across a signal, and we will display them as a "MFCC-gram":
"""

hamming_window = ess.Windowing(type='hamming')
spectrum = ess.Spectrum()  # we just want the magnitude spectrum
mfcc = ess.MFCC(numberCoefficients=13)
frame_sz = 1024
hop_sz = 500

mfccs = numpy.array([mfcc(spectrum(hamming_window(frame)))[1]
               for frame in ess.FrameGenerator(x, frameSize=frame_sz, hopSize=hop_sz)])
print mfccs.shape

mfccs1 = numpy.array([mfcc(spectrum(hamming_window(frame)))[1]
               for frame in ess.FrameGenerator(y, frameSize=frame_sz, hopSize=hop_sz)])
print mfccs1.shape

mfccs2 = numpy.array([mfcc(spectrum(hamming_window(frame)))[1]
               for frame in ess.FrameGenerator(z, frameSize=frame_sz, hopSize=hop_sz)])
print mfccs2.shape

"""Scale the MFCCs:"""

mfccs = sklearn.preprocessing.scale(mfccs)

mfccs1 = sklearn.preprocessing.scale(mfccs1)

mfccs2 = sklearn.preprocessing.scale(mfccs2)

"""Plot the MFCCs:"""

plt.imshow(mfccs.T, origin='lower', aspect='auto', interpolation='nearest')
plt.ylabel('MFCC Coefficient Index')
plt.xlabel('Frame Index')

plt.imshow(mfccs1.T, origin='lower', aspect='auto', interpolation='nearest')
plt.ylabel('MFCC Coefficient Index')
plt.xlabel('Frame Index')

plt.imshow(mfccs2.T, origin='lower', aspect='auto', interpolation='nearest')
plt.ylabel('MFCC Coefficient Index')
plt.xlabel('Frame Index')

import math
# Example points in 3-dimensional space...
def dist(a,b):
  distance = math.sqrt(sum((a - b) **2))
  print("Euclidean distance from x to y: ",distance)
  return distance

dist(mfccs,mfccs1)

"""[&larr; Back to Index](index.html)"""

from scipy.spatial import distance

print distance.cdist(mfccs, mfccs1, "euclidean")

print distance.cdist(mfccs, mfccs2, "euclidean")

print distance.cdist(mfccs1, mfccs2, "euclidean")



from librosa.display import waveplot
from librosa import load
x, fs = load('/content/drive/My Drive/PAS/Marina/MS-10.WAV')
waveplot(x, sr=fs)

IPython.display.Audio(x, rate=fs)

mfccs = librosa.feature.mfcc(x, sr=fs)
print mfccs.shape

librosa.display.specshow(mfccs, sr=fs, x_axis='time')

mfccs = sklearn.preprocessing.scale(mfccs, axis=1)
print mfccs.mean(axis=1)
print mfccs.var(axis=1)

librosa.display.specshow(mfccs, sr=fs, x_axis='time')

from librosa.display import waveplot
from librosa import load
x, fs = load('/content/drive/My Drive/PAS/Sami/SM-10.WAV')
waveplot(x, sr=fs)

IPython.display.Audio(x, rate=fs)

mfccs = librosa.feature.mfcc(x, sr=fs)
print mfccs.shape

librosa.display.specshow(mfccs, sr=fs, x_axis='time')

mfccs = sklearn.preprocessing.scale(mfccs, axis=1)
print mfccs.mean(axis=1)
print mfccs.var(axis=1)

librosa.display.specshow(mfccs, sr=fs, x_axis='time')

from librosa.display import waveplot
from librosa import load
x, fs = load('/content/drive/My Drive/PAS/Maryam/SF-10.WAV')
waveplot(x, sr=fs)

IPython.display.Audio(x, rate=fs)

mfccs = librosa.feature.mfcc(x, sr=fs)
print mfccs.shape

librosa.display.specshow(mfccs, sr=fs, x_axis='time')

mfccs = sklearn.preprocessing.scale(mfccs, axis=1)
print mfccs.mean(axis=1)
print mfccs.var(axis=1)

librosa.display.specshow(mfccs, sr=fs, x_axis='time')

"""**PCA**"""

# Commented out IPython magic to ensure Python compatibility.
import numpy, scipy, matplotlib.pyplot as plt, sklearn, urllib, IPython.display
# %matplotlib inline
plt.rcParams['figure.figsize'] = (14, 5)

!pip install librosa
import librosa

x, fs = librosa.load('/content/drive/My Drive/PAS/Maryam/SF-10.WAV')
IPython.display.Audio(x, rate=fs)

X = librosa.feature.mfcc(x, sr=fs)
print X.shape
X = sklearn.preprocessing.scale(X)
X.mean()
model = sklearn.decomposition.PCA(n_components=2, whiten=True)
model.fit(X.T)
Y1 = model.transform(X.T)
print Y1.shape

a=model.components_
print(a)
print(a.shape)

plt.scatter(Y1[:,0], Y1[:,1])

print(Y[:,0])

print(Y[:,1])

x, fs = librosa.load('/content/drive/My Drive/PAS/Marina/MS-10.WAV')
IPython.display.Audio(x, rate=fs)

X = librosa.feature.mfcc(x, sr=fs)
print X.shape
X = sklearn.preprocessing.scale(X)
X.mean()
model = sklearn.decomposition.PCA(n_components=2, whiten=True)
model.fit(X.T)
Y2 = model.transform(X.T)
print Y2.shape

b=model.components_
model.components_.shape
print(model.components_.shape)

plt.scatter(Y2[:,0], Y2[:,1])

plt.scatter(Y1[:,0],Y1[:,1])
plt.scatter(Y2[:,0],Y2[:,1])

#print(a)
#print(b)

c=a-b
print(c)
print(c.shape)

plt.plot(a, c='b')
plt.plot(b, c='r')
plt.legend(('x', 'y'))